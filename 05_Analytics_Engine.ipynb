{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60fd20fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Notebook 5: Analytics Engine ---\n",
      "Current time: 2025-05-23 09:34:34.687436+05:30\n",
      "Using Database: trend_analyzer.db\n",
      "Analyzing Topic: Advancements in Renewable Energy Technologies\n",
      "\n",
      "Imports and helper functions defined for Notebook 5.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from collections import Counter # For counting keyword frequencies\n",
    "import json # For storing list/dict like data (top_keywords) in a text field\n",
    "from datetime import date, timedelta, datetime # For date manipulations\n",
    "\n",
    "# --- Config variables (copy essential ones from Notebook 01_Setup_and_Config) ---\n",
    "DATABASE_NAME = \"trend_analyzer.db\"\n",
    "ANALYSIS_TOPIC = \"Advancements in Renewable Energy Technologies\" # Ensure this matches what's in your DB\n",
    "\n",
    "print(f\"--- Notebook 5: Analytics Engine ---\")\n",
    "print(f\"Current time: {pd.Timestamp.now(tz='Asia/Kolkata')}\") # Using your current timezone\n",
    "print(f\"Using Database: {DATABASE_NAME}\")\n",
    "print(f\"Analyzing Topic: {ANALYSIS_TOPIC}\")\n",
    "\n",
    "\n",
    "# --- Database Manager functions (subset needed for this notebook) ---\n",
    "def create_connection():\n",
    "    \"\"\"Creates a database connection to the SQLite database.\"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(DATABASE_NAME)\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"DB Connection Error: {e}\")\n",
    "    return conn\n",
    "\n",
    "def update_daily_trend_analytics(conn, trend_date_iso, avg_sentiment, top_k_str, emerging_k_str):\n",
    "    \"\"\"Inserts or updates the daily trend data for a specific date.\"\"\"\n",
    "    if not conn:\n",
    "        print(\"No database connection for update_daily_trend_analytics.\")\n",
    "        return False\n",
    "    success = False\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO daily_trends (trend_date, topic, average_sentiment_score, top_keywords, emerging_keywords)\n",
    "            VALUES (?, ?, ?, ?, ?)\n",
    "            ON CONFLICT(trend_date) DO UPDATE SET\n",
    "            topic = excluded.topic,\n",
    "            average_sentiment_score = excluded.average_sentiment_score,\n",
    "            top_keywords = excluded.top_keywords,\n",
    "            emerging_keywords = excluded.emerging_keywords;\n",
    "        \"\"\", (trend_date_iso, ANALYSIS_TOPIC, avg_sentiment, top_k_str, emerging_k_str))\n",
    "        conn.commit()\n",
    "        success = True\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error updating daily_trends for date {trend_date_iso}: {e}\")\n",
    "    return success\n",
    "\n",
    "print(\"\\nImports and helper functions defined for Notebook 5.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "363b9e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate_daily_trends function defined.\n",
      "\n",
      "--- Testing calculate_daily_trends for today ---\n",
      "--- Calculating daily trends for date: 2025-05-23 ---\n",
      "Daily trend for 2025-05-23 successfully updated/inserted into the database.\n",
      "  Avg Sentiment: 0.000\n",
      "  Top Keywords: []\n",
      "  Emerging Keywords: []\n",
      "\n",
      "--- Testing calculate_daily_trends for a specific date: 2025-05-22 ---\n",
      "--- Calculating daily trends for date: 2025-05-22 ---\n",
      "Daily trend for 2025-05-22 successfully updated/inserted into the database.\n",
      "  Avg Sentiment: 0.590\n",
      "  Top Keywords: [{\"keyword\": \"energy\", \"count\": 5}, {\"keyword\": \"said\", \"count\": 4}, {\"keyword\": \"solar\", \"count\": 4}, {\"keyword\": \"credits\", \"count\": 3}, {\"keyword\": \"new\", \"count\": 3}, {\"keyword\": \"projects\", \"count\": 3}, {\"keyword\": \"bill\", \"count\": 2}, {\"keyword\": \"ira\", \"count\": 2}, {\"keyword\": \"jobs\", \"count\": 2}, {\"keyword\": \"tax\", \"count\": 2}]\n",
      "  Emerging Keywords: [\"credits\", \"projects\", \"new\", \"tax\", \"jobs\", \"energy\", \"bill\", \"ira\", \"said\"]\n"
     ]
    }
   ],
   "source": [
    "def calculate_daily_trends(target_date_obj=None):\n",
    "    \"\"\"\n",
    "    Calculates daily trends (avg sentiment, top keywords, emerging keywords)\n",
    "    for a given target_date_obj (defaults to today) and updates the database.\n",
    "    \"\"\"\n",
    "    if target_date_obj is None:\n",
    "        target_date_obj = date.today() # Use today's date if none provided\n",
    "    \n",
    "    target_date_iso = target_date_obj.isoformat()\n",
    "    print(f\"--- Calculating daily trends for date: {target_date_iso} ---\")\n",
    "\n",
    "    conn = create_connection()\n",
    "    if conn is None:\n",
    "        print(\"Failed to create database connection for analytics. Aborting.\")\n",
    "        return\n",
    "\n",
    "    avg_sentiment = 0.0\n",
    "    top_keywords_list = []\n",
    "    emerging_kws_list = []\n",
    "\n",
    "    try:\n",
    "        # --- Average Sentiment for the target_date_obj ---\n",
    "        # Query to get sentiment scores for articles published on the target_date_obj\n",
    "        # Note: SQLite's STRFTIME can be tricky with timezone-aware datetimes if not stored as UTC text.\n",
    "        # Assuming publication_date is stored in a way that STRFTIME can correctly compare dates.\n",
    "        # If publication_date is stored as TEXT in ISO format (YYYY-MM-DD HH:MM:SS+ZZ:ZZ), then:\n",
    "        # DATE(publication_date) or SUBSTR(publication_date, 1, 10) would work.\n",
    "        # For simplicity, assuming publication_date can be compared directly with date strings.\n",
    "        \n",
    "        sentiment_query = \"\"\"\n",
    "            SELECT s.sentiment_score\n",
    "            FROM sentiments s\n",
    "            JOIN articles a ON s.article_id = a.id\n",
    "            WHERE DATE(a.publication_date) = ? \n",
    "        \"\"\"\n",
    "        df_sentiment = pd.read_sql_query(sentiment_query, conn, params=(target_date_iso,))\n",
    "        \n",
    "        if not df_sentiment.empty and 'sentiment_score' in df_sentiment.columns:\n",
    "            avg_sentiment = df_sentiment['sentiment_score'].mean()\n",
    "        else:\n",
    "            # print(f\"No sentiment data found for articles published on {target_date_iso}.\")\n",
    "            pass # avg_sentiment remains 0.0\n",
    "\n",
    "        # --- Top Keywords for the target_date_obj ---\n",
    "        keywords_query = \"\"\"\n",
    "            SELECT k.keyword \n",
    "            FROM keywords k\n",
    "            JOIN articles a ON k.article_id = a.id\n",
    "            WHERE DATE(a.publication_date) = ?\n",
    "        \"\"\"\n",
    "        df_keywords_today = pd.read_sql_query(keywords_query, conn, params=(target_date_iso,))\n",
    "        \n",
    "        if not df_keywords_today.empty and 'keyword' in df_keywords_today.columns:\n",
    "            keyword_counts_today = Counter(df_keywords_today['keyword'])\n",
    "            top_keywords_list = [{'keyword': kw, 'count': ct} for kw, ct in keyword_counts_today.most_common(10)]\n",
    "        else:\n",
    "            # print(f\"No keyword data found for articles published on {target_date_iso}.\")\n",
    "            pass\n",
    "\n",
    "        # --- Emerging Keywords (Simple: new today vs. prominent yesterday) ---\n",
    "        yesterday_date_obj = target_date_obj - timedelta(days=1)\n",
    "        yesterday_date_iso = yesterday_date_obj.isoformat()\n",
    "        \n",
    "        df_keywords_yesterday = pd.read_sql_query(keywords_query, conn, params=(yesterday_date_iso,)) # Reusing keywords_query\n",
    "        \n",
    "        yesterday_top_kws_set = set()\n",
    "        if not df_keywords_yesterday.empty and 'keyword' in df_keywords_yesterday.columns:\n",
    "            keyword_counts_yesterday = Counter(df_keywords_yesterday['keyword'])\n",
    "            # Consider keywords prominent if they were in top N yesterday, e.g., top 20\n",
    "            yesterday_top_kws_set = {kw_item[0] for kw_item in keyword_counts_yesterday.most_common(20)} \n",
    "\n",
    "        today_current_kws_set = {kw_item['keyword'] for kw_item in top_keywords_list} # Keywords from today's top list\n",
    "        \n",
    "        # Emerging = in today's list (or all of today's keywords) but not in yesterday's prominent set\n",
    "        emerging_kws_list = list(today_current_kws_set - yesterday_top_kws_set)\n",
    "        emerging_kws_list = emerging_kws_list[:10] # Limit to 10 emerging keywords\n",
    "\n",
    "        # --- Update Database ---\n",
    "        top_keywords_str = json.dumps(top_keywords_list)\n",
    "        emerging_keywords_str = json.dumps(emerging_kws_list)\n",
    "        \n",
    "        if update_daily_trend_analytics(conn, target_date_iso, avg_sentiment, top_keywords_str, emerging_keywords_str):\n",
    "            print(f\"Daily trend for {target_date_iso} successfully updated/inserted into the database.\")\n",
    "            print(f\"  Avg Sentiment: {avg_sentiment:.3f}\")\n",
    "            print(f\"  Top Keywords: {top_keywords_str}\")\n",
    "            print(f\"  Emerging Keywords: {emerging_keywords_str}\")\n",
    "        else:\n",
    "            print(f\"Failed to update daily trend for {target_date_iso} in the database.\")\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"SQLite error during analytics calculation for {target_date_iso}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during analytics for {target_date_iso}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "            # print(f\"Database connection closed for {target_date_iso} analytics.\")\n",
    "\n",
    "print(\"calculate_daily_trends function defined.\")\n",
    "\n",
    "# --- Test the function for today ---\n",
    "# Note: This test assumes that Notebook 4 (Data Storage and Pipeline) has been run\n",
    "# and populated the database with articles, including some for \"today\" or a recent date.\n",
    "# If your database is empty or has no data for \"today\", the analytics will be based on no data.\n",
    "\n",
    "print(\"\\n--- Testing calculate_daily_trends for today ---\")\n",
    "# Before running this, ensure your database actually HAS data for \"today\"\n",
    "# or a specific date you want to test.\n",
    "# If running for the first time and Notebook 4 just ran, \"today\" should have data.\n",
    "calculate_daily_trends() \n",
    "\n",
    "# Example: To test for a specific past date (if you have historical data)\n",
    "specific_test_date = date(2025, 5, 22) # Year, Month, Day\n",
    "print(f\"\\n--- Testing calculate_daily_trends for a specific date: {specific_test_date.isoformat()} ---\")\n",
    "calculate_daily_trends(target_date_obj=specific_test_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0846d5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking data based on UTC conversion ---\n",
      "\n",
      "--- Articles with UTC publication_date = '2025-05-22' ---\n",
      "Found 13 articles for UTC date 2025-05-22:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_name</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>scraped_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>RenewableEnergySub r/RenewableEnergy</td>\n",
       "      <td>House GOP moves to slash renewable energy tax ...</td>\n",
       "      <td>2025-05-22 20:01:50+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>RenewableEnergySub r/RenewableEnergy</td>\n",
       "      <td>Alabama enacts ‘all-of-the-above’ energy plan</td>\n",
       "      <td>2025-05-22 18:39:16+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>Ars Technica</td>\n",
       "      <td>In 3.5 years, Notepad.exe has gone from “barel...</td>\n",
       "      <td>2025-05-22 17:16:32+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Ars Technica</td>\n",
       "      <td>The Pentagon seems to be fed up with ULA’s roc...</td>\n",
       "      <td>2025-05-22 17:02:48+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Ars Technica</td>\n",
       "      <td>Why console makers can legally brick your game...</td>\n",
       "      <td>2025-05-22 16:39:04+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                           source_name  \\\n",
       "0  11  RenewableEnergySub r/RenewableEnergy   \n",
       "1  12  RenewableEnergySub r/RenewableEnergy   \n",
       "2   6                          Ars Technica   \n",
       "3   7                          Ars Technica   \n",
       "4   8                          Ars Technica   \n",
       "\n",
       "                                               title  \\\n",
       "0  House GOP moves to slash renewable energy tax ...   \n",
       "1      Alabama enacts ‘all-of-the-above’ energy plan   \n",
       "2  In 3.5 years, Notepad.exe has gone from “barel...   \n",
       "3  The Pentagon seems to be fed up with ULA’s roc...   \n",
       "4  Why console makers can legally brick your game...   \n",
       "\n",
       "            publication_date         scraped_date  \n",
       "0  2025-05-22 20:01:50+00:00  2025-05-23 04:02:33  \n",
       "1  2025-05-22 18:39:16+00:00  2025-05-23 04:02:33  \n",
       "2  2025-05-22 17:16:32+00:00  2025-05-23 04:02:33  \n",
       "3  2025-05-22 17:02:48+00:00  2025-05-23 04:02:33  \n",
       "4  2025-05-22 16:39:04+00:00  2025-05-23 04:02:33  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Articles with UTC publication_date = '2025-05-23' ---\n",
      "No articles found with a UTC publication_date of 2025-05-23.\n",
      "\n",
      "--- Most Recent 20 Articles (to see their actual publication dates) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source_name</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>scraped_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Guardian Environment</td>\n",
       "      <td>Revealed: three tonnes of uranium legally dump...</td>\n",
       "      <td>2025-05-22 08:30:33+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Guardian Environment</td>\n",
       "      <td>‘Unprecedented’ marine heatwave hits waters ar...</td>\n",
       "      <td>2025-05-22 07:57:36+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Guardian Environment</td>\n",
       "      <td>How an idealistic tree-planting project turned...</td>\n",
       "      <td>2025-05-21 23:30:49+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Guardian Environment</td>\n",
       "      <td>‘Waste collection is green work’: how a pro-po...</td>\n",
       "      <td>2025-05-22 08:10:29+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Guardian Environment</td>\n",
       "      <td>Trump’s tax bill to cost 830,000 jobs and driv...</td>\n",
       "      <td>2025-05-22 05:30:09+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Ars Technica</td>\n",
       "      <td>In 3.5 years, Notepad.exe has gone from “barel...</td>\n",
       "      <td>2025-05-22 17:16:32+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Ars Technica</td>\n",
       "      <td>The Pentagon seems to be fed up with ULA’s roc...</td>\n",
       "      <td>2025-05-22 17:02:48+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Ars Technica</td>\n",
       "      <td>Why console makers can legally brick your game...</td>\n",
       "      <td>2025-05-22 16:39:04+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Ars Technica</td>\n",
       "      <td>Musk’s DOGE used Meta’s Llama 2—not Grok—for g...</td>\n",
       "      <td>2025-05-22 15:42:22+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Ars Technica</td>\n",
       "      <td>Gouach wants you to insert and pluck the cells...</td>\n",
       "      <td>2025-05-22 14:42:13+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>RenewableEnergySub r/RenewableEnergy</td>\n",
       "      <td>House GOP moves to slash renewable energy tax ...</td>\n",
       "      <td>2025-05-22 20:01:50+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>RenewableEnergySub r/RenewableEnergy</td>\n",
       "      <td>Alabama enacts ‘all-of-the-above’ energy plan</td>\n",
       "      <td>2025-05-22 18:39:16+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>RenewableEnergySub r/RenewableEnergy</td>\n",
       "      <td>Fluence just took a big step to make grid batt...</td>\n",
       "      <td>2025-05-22 12:01:57+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>RenewableEnergySub r/RenewableEnergy</td>\n",
       "      <td>New York awards contracts for 26 large-scale r...</td>\n",
       "      <td>2025-05-22 10:59:12+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>RenewableEnergySub r/RenewableEnergy</td>\n",
       "      <td>US redirects $365 million Biden had set for Pu...</td>\n",
       "      <td>2025-05-21 19:49:54+00:00</td>\n",
       "      <td>2025-05-23 04:02:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                           source_name  \\\n",
       "0    1                  Guardian Environment   \n",
       "1    2                  Guardian Environment   \n",
       "2    3                  Guardian Environment   \n",
       "3    4                  Guardian Environment   \n",
       "4    5                  Guardian Environment   \n",
       "5    6                          Ars Technica   \n",
       "6    7                          Ars Technica   \n",
       "7    8                          Ars Technica   \n",
       "8    9                          Ars Technica   \n",
       "9   10                          Ars Technica   \n",
       "10  11  RenewableEnergySub r/RenewableEnergy   \n",
       "11  12  RenewableEnergySub r/RenewableEnergy   \n",
       "12  13  RenewableEnergySub r/RenewableEnergy   \n",
       "13  14  RenewableEnergySub r/RenewableEnergy   \n",
       "14  15  RenewableEnergySub r/RenewableEnergy   \n",
       "\n",
       "                                                title  \\\n",
       "0   Revealed: three tonnes of uranium legally dump...   \n",
       "1   ‘Unprecedented’ marine heatwave hits waters ar...   \n",
       "2   How an idealistic tree-planting project turned...   \n",
       "3   ‘Waste collection is green work’: how a pro-po...   \n",
       "4   Trump’s tax bill to cost 830,000 jobs and driv...   \n",
       "5   In 3.5 years, Notepad.exe has gone from “barel...   \n",
       "6   The Pentagon seems to be fed up with ULA’s roc...   \n",
       "7   Why console makers can legally brick your game...   \n",
       "8   Musk’s DOGE used Meta’s Llama 2—not Grok—for g...   \n",
       "9   Gouach wants you to insert and pluck the cells...   \n",
       "10  House GOP moves to slash renewable energy tax ...   \n",
       "11      Alabama enacts ‘all-of-the-above’ energy plan   \n",
       "12  Fluence just took a big step to make grid batt...   \n",
       "13  New York awards contracts for 26 large-scale r...   \n",
       "14  US redirects $365 million Biden had set for Pu...   \n",
       "\n",
       "             publication_date         scraped_date  \n",
       "0   2025-05-22 08:30:33+00:00  2025-05-23 04:02:33  \n",
       "1   2025-05-22 07:57:36+00:00  2025-05-23 04:02:33  \n",
       "2   2025-05-21 23:30:49+00:00  2025-05-23 04:02:33  \n",
       "3   2025-05-22 08:10:29+00:00  2025-05-23 04:02:33  \n",
       "4   2025-05-22 05:30:09+00:00  2025-05-23 04:02:33  \n",
       "5   2025-05-22 17:16:32+00:00  2025-05-23 04:02:33  \n",
       "6   2025-05-22 17:02:48+00:00  2025-05-23 04:02:33  \n",
       "7   2025-05-22 16:39:04+00:00  2025-05-23 04:02:33  \n",
       "8   2025-05-22 15:42:22+00:00  2025-05-23 04:02:33  \n",
       "9   2025-05-22 14:42:13+00:00  2025-05-23 04:02:33  \n",
       "10  2025-05-22 20:01:50+00:00  2025-05-23 04:02:33  \n",
       "11  2025-05-22 18:39:16+00:00  2025-05-23 04:02:33  \n",
       "12  2025-05-22 12:01:57+00:00  2025-05-23 04:02:33  \n",
       "13  2025-05-22 10:59:12+00:00  2025-05-23 04:02:33  \n",
       "14  2025-05-21 19:49:54+00:00  2025-05-23 04:02:33  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 3: Query and Display Articles for Relevant UTC Dates\n",
    "from datetime import date, timedelta # <<< CORRECTED IMPORT\n",
    "\n",
    "print(f\"--- Checking data based on UTC conversion ---\")\n",
    "conn_check = create_connection() # Assumes create_connection is defined in Cell 1\n",
    "if conn_check:\n",
    "    try:\n",
    "        # Dates to check (UTC)\n",
    "        # Your May 23rd IST could include articles published late May 22nd UTC or early May 23rd UTC\n",
    "        dates_to_check_iso = [\n",
    "            (date.today() - timedelta(days=1)).isoformat(), # Yesterday UTC\n",
    "            date.today().isoformat()                         # Today UTC\n",
    "        ]\n",
    "        \n",
    "        for check_date_iso in dates_to_check_iso:\n",
    "            print(f\"\\n--- Articles with UTC publication_date = '{check_date_iso}' ---\")\n",
    "            # Ensure pandas is imported if you use display(df)\n",
    "            # import pandas as pd \n",
    "            df_articles_for_date = pd.read_sql_query(\"\"\"\n",
    "                SELECT id, source_name, title, publication_date, scraped_date\n",
    "                FROM articles\n",
    "                WHERE DATE(publication_date) = ? \n",
    "                ORDER BY publication_date DESC\n",
    "            \"\"\", conn_check, params=(check_date_iso,))\n",
    "            \n",
    "            if not df_articles_for_date.empty:\n",
    "                print(f\"Found {len(df_articles_for_date)} articles for UTC date {check_date_iso}:\")\n",
    "                display(df_articles_for_date.head()) # Make sure to import/use display if not default\n",
    "            else:\n",
    "                print(f\"No articles found with a UTC publication_date of {check_date_iso}.\")\n",
    "        \n",
    "        print(\"\\n--- Most Recent 20 Articles (to see their actual publication dates) ---\")\n",
    "        df_recent_articles = pd.read_sql_query(\"\"\"\n",
    "            SELECT id, source_name, title, publication_date, scraped_date\n",
    "            FROM articles\n",
    "            ORDER BY scraped_date DESC \n",
    "            LIMIT 20\n",
    "        \"\"\", conn_check)\n",
    "        if not df_recent_articles.empty:\n",
    "            display(df_recent_articles) # Make sure to import/use display if not default\n",
    "        else:\n",
    "            print(\"No articles found in the database at all.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying database in Cell 3: {e}\")\n",
    "    finally:\n",
    "        conn_check.close()\n",
    "else:\n",
    "    print(\"Could not connect to database to check data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d7957d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
