{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ff034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook 1: Setup, Configuration, and Database Initialization\n",
    "#This notebook sets up the project configuration variables and initializes the SQLite database and its tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "296b0b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project configuration variables loaded.\n",
      "Database will be: trend_analyzer.db\n",
      "Analysis Topic set to: Advancements in Renewable Energy Technologies\n",
      "RSS Feeds configured: ['Guardian Environment', 'Ars Technica']\n",
      "Subreddits configured: ['RenewableEnergy']\n"
     ]
    }
   ],
   "source": [
    "# --- Project Configuration Variables ---\n",
    "\n",
    "# Defines the central theme for news and social media analysis\n",
    "ANALYSIS_TOPIC = \"Advancements in Renewable Energy Technologies\"\n",
    "\n",
    "# Dictionary of RSS feeds to be scraped for news articles\n",
    "# Ensure these URLs are active and relevant to the ANALYSIS_TOPIC.\n",
    "NEWS_RSS_FEEDS = {\n",
    "    \"Guardian Environment\": \"https://www.theguardian.com/environment/rss\",\n",
    "    \"Ars Technica\": \"http://feeds.arstechnica.com/arstechnica/index/\" # Example working feed\n",
    "    # Add other relevant and verified RSS feeds here.\n",
    "}\n",
    "\n",
    "# Configuration for scraping Reddit\n",
    "REDDIT_SUBREDDITS = {\n",
    "    \"RenewableEnergySub\": \"RenewableEnergy\" # Internal key maps to subreddit name\n",
    "}\n",
    "# Number of recent posts to fetch from each Reddit source per scraping cycle\n",
    "REDDIT_POST_LIMIT = 10 # Adjusted for efficient testing; can be increased.\n",
    "\n",
    "# Filename for the SQLite database\n",
    "DATABASE_NAME = \"trend_analyzer.db\"\n",
    "\n",
    "# Interval for the automated scheduler (in seconds)\n",
    "# This is primarily for the standalone app_scheduler.py script.\n",
    "SCHEDULER_INTERVAL_SECONDS = 3600 # e.g., 1 hour\n",
    "\n",
    "print(\"Project configuration variables loaded.\")\n",
    "print(f\"Database will be: {DATABASE_NAME}\")\n",
    "print(f\"Analysis Topic set to: {ANALYSIS_TOPIC}\")\n",
    "print(f\"RSS Feeds configured: {list(NEWS_RSS_FEEDS.keys())}\")\n",
    "print(f\"Subreddits configured: {list(REDDIT_SUBREDDITS.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ad2cb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database management functions (create_connection, create_tables) are defined.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "from datetime import datetime # Not strictly needed in this cell if not used by these functions\n",
    "\n",
    "# Assumes DATABASE_NAME and ANALYSIS_TOPIC are defined in the previous cell (Cell 2).\n",
    "\n",
    "def create_connection():\n",
    "    \"\"\"Establishes a connection to the SQLite database.\"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # Uses DATABASE_NAME from the global scope (defined in Cell 2)\n",
    "        conn = sqlite3.connect(DATABASE_NAME)\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"SQLite Error: Could not connect to database '{DATABASE_NAME}'. Reason: {e}\")\n",
    "    return conn\n",
    "\n",
    "def create_tables():\n",
    "    \"\"\"Creates all necessary tables in the database if they don't already exist.\"\"\"\n",
    "    conn = create_connection()\n",
    "    if conn is not None:\n",
    "        try:\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            # --- Articles Table ---\n",
    "            # Stores information about each scraped article or post.\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS articles (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    source_url TEXT UNIQUE NOT NULL, -- Ensures each article is stored only once based on its URL\n",
    "                    source_name TEXT,                 -- e.g., 'Guardian Environment', 'Reddit r/RenewableEnergy'\n",
    "                    title TEXT,\n",
    "                    raw_content TEXT,                 -- The initially scraped, unprocessed content\n",
    "                    processed_content TEXT,           -- (Optional) For cleaned or main extracted text\n",
    "                    publication_date TIMESTAMP,       -- Standardized to UTC\n",
    "                    scraped_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP -- When the article was added to our DB\n",
    "                );\n",
    "            \"\"\")\n",
    "            \n",
    "            # --- Sentiments Table ---\n",
    "            # Stores sentiment analysis results for each article.\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS sentiments (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    article_id INTEGER NOT NULL,      -- Foreign key linking to the articles table\n",
    "                    sentiment_score REAL,             -- e.g., VADER compound score (-1 to 1)\n",
    "                    sentiment_label TEXT,             -- e.g., 'positive', 'negative', 'neutral'\n",
    "                    FOREIGN KEY (article_id) REFERENCES articles (id) ON DELETE CASCADE\n",
    "                );\n",
    "            \"\"\")\n",
    "            \n",
    "            # --- Keywords Table ---\n",
    "            # Stores extracted keywords and their scores for each article.\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS keywords (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    article_id INTEGER NOT NULL,      -- Foreign key\n",
    "                    keyword TEXT NOT NULL,\n",
    "                    score REAL,                       -- e.g., TF-IDF score\n",
    "                    FOREIGN KEY (article_id) REFERENCES articles (id) ON DELETE CASCADE,\n",
    "                    UNIQUE (article_id, keyword)      -- Prevents duplicate keywords for the same article\n",
    "                );\n",
    "            \"\"\")\n",
    "            \n",
    "            # --- Entities Table ---\n",
    "            # Stores named entities extracted from each article.\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS entities (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    article_id INTEGER NOT NULL,      -- Foreign key\n",
    "                    entity_text TEXT NOT NULL,        -- The text of the entity (e.g., \"SolarCorp\")\n",
    "                    entity_label TEXT,                -- The entity type (e.g., \"ORG\", \"PERSON\")\n",
    "                    FOREIGN KEY (article_id) REFERENCES articles (id) ON DELETE CASCADE\n",
    "                );\n",
    "            \"\"\")\n",
    "            \n",
    "            # --- Daily Trends Table ---\n",
    "            # Stores aggregated daily analytics for the main topic.\n",
    "            # Uses ANALYSIS_TOPIC from the global scope (defined in Cell 2) for the default topic.\n",
    "            # The .replace(\"'\", \"''\") is crucial for safely embedding a string with potential single quotes into an SQL DEFAULT clause.\n",
    "            escaped_analysis_topic = ANALYSIS_TOPIC.replace(\"'\", \"''\")\n",
    "            cursor.execute(f\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS daily_trends (\n",
    "                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    trend_date DATE UNIQUE NOT NULL,    -- The specific date for which trends are calculated\n",
    "                    topic TEXT DEFAULT '{escaped_analysis_topic}', \n",
    "                    average_sentiment_score REAL,\n",
    "                    top_keywords TEXT,                  -- JSON string of top keywords and their frequencies\n",
    "                    emerging_keywords TEXT              -- JSON string of newly prominent keywords\n",
    "                );\n",
    "            \"\"\")\n",
    "            \n",
    "            conn.commit()\n",
    "            print(\"Database tables checked/created successfully.\")\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"SQLite Error: Could not create tables. Reason: {e}\")\n",
    "        finally:\n",
    "            conn.close()\n",
    "    else:\n",
    "        print(\"SQLite Error: Database connection could not be established for table creation.\")\n",
    "\n",
    "print(\"Database management functions (create_connection, create_tables) are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7880d615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to initialize database and create tables...\n",
      "Database tables checked/created successfully.\n",
      "Database initialization sequence finished.\n"
     ]
    }
   ],
   "source": [
    "# This cell executes the create_tables function to ensure the database schema is in place.\n",
    "\n",
    "print(\"Attempting to initialize database and create tables...\")\n",
    "create_tables() # Calls the function defined in the previous cell\n",
    "print(\"Database initialization sequence finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3049e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
